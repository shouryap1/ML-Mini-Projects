{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "877a2362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a88d3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self,position_in_layer,is_output_neuron=False):\n",
    "        self.weights=[]\n",
    "        self.inputs=[]\n",
    "        self.output=None\n",
    "        self.updated_weights=[]   #helpful for backpropogation update\n",
    "        self.is_output_neuron=is_output_neuron\n",
    "        self.delta=None           #used in backpropogation for update\n",
    "        self.position_in_layer=position_in_layer\n",
    "        \n",
    "    def attach_to_output(self,neurons):\n",
    "        self.output_neurons=neurons\n",
    "        \n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return (1 / (1 + math.exp(-x)))\n",
    "    \n",
    "    \n",
    "    def init_weights(self, num_input):    #helps in initializing weights[currently done randomly using the random function]\n",
    "        for i in range(num_input+1):\n",
    "            self.weights.append(random.uniform(0,1))   \n",
    "            \n",
    "            \n",
    "    def predict(self, row):\n",
    "        self.inputs = []\n",
    "        activation = 0\n",
    "        for weight, feature in zip(self.weights, row):\n",
    "            self.inputs.append(feature)\n",
    "            activation = activation + (weight*feature)\n",
    "        self.output = self.sigmoid(activation)\n",
    "        return self.output    \n",
    "            \n",
    "    def update_neuron(self):\n",
    "        self.weights = []\n",
    "        for new_weight in self.updated_weights:\n",
    "            self.weights.append(new_weight)\n",
    "            \n",
    "    def calculate_update(self, learning_rate, target):\n",
    "        if self.is_output_neuron:\n",
    "            self.delta = (self.output - target)*self.output*(1-self.output)\n",
    "        else:\n",
    "            delta_sum = 0\n",
    "            cur_weight_index = self.position_in_layer             # this is to know which weights this neuron is contributing in the output layer\n",
    "            for output_neuron in self.output_neurons:\n",
    "                delta_sum = delta_sum + (output_neuron.delta * output_neuron.weights[cur_weight_index])\n",
    "\n",
    "            self.delta = delta_sum*self.output*(1-self.output)              # Update this neuron delta\n",
    "            \n",
    "        self.updated_weights = []   #dont have to overwrite the weights as earlier ones has to be used for other updates in backpropagation\n",
    "        \n",
    "        # Iterate over each weight and update them\n",
    "        for cur_weight, cur_input in zip(self.weights, self.inputs):\n",
    "            gradient = self.delta*cur_input\n",
    "            new_weight = cur_weight - learning_rate*gradient\n",
    "            self.updated_weights.append(new_weight)        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77892bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, num_neuron, is_output_layer = False):\n",
    "        self.is_output_layer = is_output_layer\n",
    "        self.neurons = []\n",
    "        for i in range(num_neuron):                         # Will create that much neurons in the layer\n",
    "            neuron = Neuron(i,  is_output_neuron=is_output_layer)\n",
    "            self.neurons.append(neuron)\n",
    "    \n",
    "    def attach(self, layer):\n",
    "        for in_neuron in self.neurons:\n",
    "            in_neuron.attach_to_output(layer.neurons)\n",
    "            \n",
    "    def init_layer(self, num_input):\n",
    "        for neuron in self.neurons:\n",
    "            neuron.init_weights(num_input)\n",
    "    \n",
    "    def predict(self, row):\n",
    "        row.append(1) \n",
    "        activations = [neuron.predict(row) for neuron in self.neurons]\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b1c5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron():          #will be creating the multi-layer perceptron with only two layer only\n",
    "\n",
    "    def __init__(self, learning_rate = 0.01, num_iteration = 100):\n",
    "        self.layers = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iteration = num_iteration\n",
    "        \n",
    "        \n",
    "    def add_output_layer(self, num_neuron):\n",
    "        self.layers.insert(0, Layer(num_neuron, is_output_layer = True))\n",
    "    \n",
    "    def add_hidden_layer(self, num_neuron):\n",
    "        hidden_layer = Layer(num_neuron) # Created an hidden layer\n",
    "        hidden_layer.attach(self.layers[0])  # Attached the last added layer to this new layer\n",
    "        self.layers.insert(0, hidden_layer)  # Added this layer to the whole network\n",
    "        \n",
    "    def update_layers(self, target):\n",
    "        for layer in reversed(self.layers):\n",
    "            for neuron in layer.neurons:\n",
    "                neuron.calculate_update(self.learning_rate, target)  \n",
    "        for layer in self.layers:\n",
    "            for neuron in layer.neurons:\n",
    "                neuron.update_neuron()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_row = len(X)\n",
    "        num_feature = len(X[0]) #We assume that we have a rectangular matrix\n",
    "        \n",
    "        # Initialized the weights throughout each of the layer\n",
    "        self.layers[0].init_layer(num_feature)\n",
    "        \n",
    "        for i in range(1, len(self.layers)):\n",
    "            num_input = len(self.layers[i-1].neurons)\n",
    "            self.layers[i].init_layer(num_input)\n",
    "\n",
    "        #Running the algorithm\n",
    "        for i in range(self.num_iteration):\n",
    "            # Stochastic Gradient Descent\n",
    "            r_i = random.randint(0,num_row-1)\n",
    "            row = X[r_i] # taking the random sample from the dataset\n",
    "            yhat = self.predict(row)\n",
    "            target = y[r_i]\n",
    "            \n",
    "            # Updated the layers using backpropagation   \n",
    "            self.update_layers(target)\n",
    "            \n",
    "            # on every 100 iteration we calculate the error on the whole training set\n",
    "            if i % 1000 == 0:\n",
    "                total_error = 0\n",
    "                for r_i in range(num_row):\n",
    "                    row = X[r_i]\n",
    "                    yhat = self.predict(row)\n",
    "                    error = (y[r_i] - yhat)\n",
    "                    total_error = total_error + error**2\n",
    "                mean_error = total_error/num_row\n",
    "                print(f\"Itr {i} with error = {mean_error}\")\n",
    "        \n",
    "    \n",
    "    def predict(self, row):        \n",
    "        activations = self.layers[0].predict(row)\n",
    "        for i in range(1, len(self.layers)):\n",
    "            activations = self.layers[i].predict(activations)\n",
    "\n",
    "        outputs = []\n",
    "        for activation in activations:                        # For having the output either 1 or 0\n",
    "            if activation >= 0.5:\n",
    "                outputs.append(1.0)\n",
    "            else:\n",
    "                outputs.append(0.0)\n",
    "                           \n",
    "        return outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "178803e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itr 0 with error = 0.75\n",
      "Itr 1000 with error = 0.25\n",
      "Itr 2000 with error = 0.25\n",
      "Itr 3000 with error = 0.25\n",
      "Itr 4000 with error = 0.25\n",
      "Itr 5000 with error = 0.25\n",
      "Itr 6000 with error = 0.25\n",
      "Itr 7000 with error = 0.25\n",
      "Itr 8000 with error = 0.25\n",
      "Itr 9000 with error = 0.25\n",
      "Itr 10000 with error = 0.25\n",
      "Itr 11000 with error = 0.25\n",
      "Itr 12000 with error = 0.25\n",
      "Itr 13000 with error = 0.0\n",
      "Itr 14000 with error = 0.0\n",
      "Itr 15000 with error = 0.0\n",
      "Itr 16000 with error = 0.0\n",
      "Itr 17000 with error = 0.0\n",
      "Itr 18000 with error = 0.0\n",
      "Itr 19000 with error = 0.0\n"
     ]
    }
   ],
   "source": [
    "X = [[0,0], [0,1], [1,0], [1,1]]                   #Random boolean function\n",
    "y = [0, 0, 1, 0]\n",
    "\n",
    "a= MultiLayerPerceptron(learning_rate = 0.1, num_iteration = 20000) #parameters for the network\n",
    "\n",
    "a.add_output_layer(num_neuron = 1)\n",
    "a.add_hidden_layer(num_neuron = 3)\n",
    "a.add_hidden_layer(num_neuron = 2)\n",
    "\n",
    "a.fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
